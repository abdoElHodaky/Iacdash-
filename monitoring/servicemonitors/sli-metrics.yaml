apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sli-metrics
  namespace: monitoring
  labels:
    app: sli-monitoring
    release: prometheus
spec:
  selector:
    matchLabels:
      app: sli-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    scheme: http
  namespaceSelector:
    matchNames:
    - monitoring
    - default
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sli-exporter
  namespace: monitoring
  labels:
    app: sli-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sli-exporter
  template:
    metadata:
      labels:
        app: sli-exporter
    spec:
      containers:
      - name: sli-exporter
        image: prom/node-exporter:latest
        ports:
        - containerPort: 9100
          name: metrics
        env:
        - name: DEPLOYMENT_START_TIME
          value: "{{ .Values.deploymentStartTime | default (now | unixEpoch) }}"
        command:
        - /bin/sh
        - -c
        - |
          cat > /tmp/sli_metrics.prom << 'EOF'
          # HELP deployment_duration_seconds Time taken for deployments
          # TYPE deployment_duration_seconds gauge
          deployment_duration_seconds{environment="dev"} 180
          deployment_duration_seconds{environment="staging"} 240
          deployment_duration_seconds{environment="production"} 300
          
          # HELP cost_savings_percentage Infrastructure cost savings percentage
          # TYPE cost_savings_percentage gauge
          cost_savings_percentage{provider="linode"} 25
          cost_savings_percentage{provider="gke"} 30
          cost_savings_percentage{provider="kind"} 100
          
          # HELP slo_target SLO targets for different metrics
          # TYPE slo_target gauge
          slo_target{metric="latency_p95_ms"} 100
          slo_target{metric="mtls_coverage_percent"} 100
          slo_target{metric="uptime_percent"} 99.99
          slo_target{metric="deployment_improvement_percent"} 50
          slo_target{metric="cost_savings_percent"} 30
          
          # HELP slo_error_budget_remaining Remaining error budget for SLOs
          # TYPE slo_error_budget_remaining gauge
          slo_error_budget_remaining{slo="latency"} 0.95
          slo_error_budget_remaining{slo="availability"} 0.98
          slo_error_budget_remaining{slo="security"} 1.0
          
          # HELP feature_flag_enabled Feature flags for different capabilities
          # TYPE feature_flag_enabled gauge
          feature_flag_enabled{feature="wasm_transformations"} 1
          feature_flag_enabled{feature="opa_policies"} 1
          feature_flag_enabled{feature="flagger_canary"} 0
          feature_flag_enabled{feature="external_secrets"} 0
          feature_flag_enabled{feature="cert_manager"} 0
          
          # HELP infrastructure_maturity_score Maturity score for different infrastructure components
          # TYPE infrastructure_maturity_score gauge
          infrastructure_maturity_score{component="gateway_api"} 0.9
          infrastructure_maturity_score{component="service_mesh"} 0.85
          infrastructure_maturity_score{component="monitoring"} 0.8
          infrastructure_maturity_score{component="security"} 0.75
          infrastructure_maturity_score{component="gitops"} 0.7
          EOF
          
          # Start node exporter with custom metrics
          /bin/node_exporter --web.listen-address=:9100 --collector.textfile.directory=/tmp &
          
          # Keep container running and update metrics periodically
          while true; do
            # Update deployment duration based on recent deployments
            CURRENT_TIME=$(date +%s)
            LAST_DEPLOYMENT_TIME=${DEPLOYMENT_START_TIME:-$CURRENT_TIME}
            DEPLOYMENT_DURATION=$((CURRENT_TIME - LAST_DEPLOYMENT_TIME))
            
            # Update metrics file
            sed -i "s/deployment_duration_seconds{environment=\"dev\"} .*/deployment_duration_seconds{environment=\"dev\"} $DEPLOYMENT_DURATION/" /tmp/sli_metrics.prom
            
            sleep 60
          done
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9100
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9100
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: sli-exporter
  namespace: monitoring
  labels:
    app: sli-exporter
spec:
  selector:
    app: sli-exporter
  ports:
  - name: metrics
    port: 9100
    targetPort: 9100
    protocol: TCP
  type: ClusterIP
---
# Custom metrics for deployment tracking
apiVersion: v1
kind: ConfigMap
metadata:
  name: deployment-tracker
  namespace: monitoring
data:
  track-deployment.sh: |
    #!/bin/bash
    # Script to track deployment metrics
    
    DEPLOYMENT_START=$(date +%s)
    echo "deployment_start_time $DEPLOYMENT_START" > /tmp/deployment_metrics.prom
    
    # Wait for deployment to complete (customize based on your deployment process)
    kubectl rollout status deployment/$1 -n $2 --timeout=600s
    
    DEPLOYMENT_END=$(date +%s)
    DEPLOYMENT_DURATION=$((DEPLOYMENT_END - DEPLOYMENT_START))
    
    echo "deployment_duration_seconds{deployment=\"$1\",namespace=\"$2\"} $DEPLOYMENT_DURATION" >> /tmp/deployment_metrics.prom
    echo "deployment_success{deployment=\"$1\",namespace=\"$2\"} 1" >> /tmp/deployment_metrics.prom
    
    # Send metrics to pushgateway or update file for node exporter
    curl -X POST http://pushgateway.monitoring:9091/metrics/job/deployment_tracker/instance/$1 \
         --data-binary @/tmp/deployment_metrics.prom
---
# Job to calculate cost savings
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cost-calculator
  namespace: monitoring
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: cost-calculator
            image: alpine/curl:latest
            command:
            - /bin/sh
            - -c
            - |
              # Calculate cost savings based on resource utilization
              # This is a simplified example - integrate with your cloud provider's billing API
              
              BASELINE_COST=1000  # Monthly baseline cost
              CURRENT_NODES=$(kubectl get nodes --no-headers | wc -l)
              BASELINE_NODES=10
              
              COST_SAVINGS=$(( (BASELINE_NODES - CURRENT_NODES) * 100 / BASELINE_NODES ))
              
              cat > /tmp/cost_metrics.prom << EOF
              cost_savings_percentage{calculation_time="$(date +%s)"} $COST_SAVINGS
              current_monthly_cost{currency="USD"} $(( BASELINE_COST * CURRENT_NODES / BASELINE_NODES ))
              baseline_monthly_cost{currency="USD"} $BASELINE_COST
              EOF
              
              # Update metrics (in real implementation, send to monitoring system)
              echo "Cost savings: $COST_SAVINGS%"
              echo "Current nodes: $CURRENT_NODES"
              echo "Baseline nodes: $BASELINE_NODES"
            resources:
              requests:
                cpu: 50m
                memory: 64Mi
              limits:
                cpu: 100m
                memory: 128Mi

